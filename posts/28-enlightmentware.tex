
\documentclass{article}

\title{Enlightmentware}
\subtitle{Software that makes you a better programmer.}
\date{2024-05-31}
\modified{2024-05-31}
\keyword{programming}

\begin{document}
\section*
As programmers, we interact with software tools daily.
Most of these systems are merely tools to get the job done.
But once in a white, we discover a piece of software that transcends mere utility.
These tools capture our imagination, open a new world of possibilities, and affect how we design our systems.
I call such software \em{enlightmentware}.

The most common source of enlightenment for programmers is the programming language they use at work or learn as a hobby.
I also experienced many jolts of enlightenment from expressing my thoughts in programming languages, from \href{https://en.wikipedia.org/wiki/Microsoft_Macro_Assembler}{\sc{masm}} and \href{https://en.wikipedia.org/wiki/C_(programming_language)}{C} to \href{https://en.wikipedia.org/wiki/Prolog}{Prolog} and \href{https://www.idris-lang.org/}{Idris}.
Many articles, however, already explain why you should many languages and how they will expand your mind\sidenote{sn-norvig}{
  See, for example, Peter Norvig's ``\href{https://norvig.com/21-days.html}{Teach Yourself Programming in Ten Years}''.
}, so I won't focus on languages here.

This article describes how various software artifacts entered my life to become my enlightmentware.

\section{unix}{UNIX}

\epigraph{
  \sc{unix} is user-friendly---it's just choosy about who its friends are.
}{
  Anonymous, in the ``Art of \sc{unix} Programming'' by Eric S. Raymond
}

Around 2008, while studying at university in my hometown of Nizhny Novgorod, I started looking for my first real programming job.
Almost all the positions I could find required knowledge of some mysterious things called \sc{unix} and \em{sockets}.
My university program didn't offer a course \sc{unix} or operating systems in general, so I did what my education taught me: get a textbook and master the topic myself. 

``\href{https://www.goodreads.com/book/show/22066650-unix}{The \sc{unix} Operating System}'' by Andrey Robachevsky et al., also known as the \em{turtle book} in Russia because of its cover, introduced me to the magical world of \sc{unix}-like operating systems.
Finally, the operating system got a clear boundary in my head and became something I could understand, explore, and programmatically interact with.
All pieces of the puzzle---the filesystem interface, the process model with environments and permissions, forking, sockets, and signals---fell into place and revealed a coherent, beautiful picture.

A search for a working \sc{unix} installation led me to \href{https://en.wikipedia.org/wiki/Mandriva_Linux}{Mandriva Linux}.
This discovery was exhilarating.
It was like entering a parallel universe where you don't have to pirate software or spend forty minutes installing an \sc{ide} to compile a \sc{c} program.
Here, people developed software for fun and shared it freely.
I couldn't fathom why anyone would use Windows\sidenote{sn-windows}{
  I became significantly more tolerant since my early university years.
  Windows (specifically the \href{https://en.wikipedia.org/wiki/Windows_NT}{NT family}) is a great operating system.
  I even have it installed on my gaming \sc{pc}.
}.

From that moment on, \sc{unix} followed me through all stages of my life:
the toddler phase of keeping up with the cutting-edge \href{https://ubuntu.com}{Ubuntu} releases,
the rebellious teens of compiling custom kernels for my \href{https://www.thinkwiki.org/wiki/Category:T61p}{Thinkpad T61p} and \href{https://wiki.gentoo.org/wiki/Emerge}{emerging} the \href{https://wiki.gentoo.org/wiki/World_set_(Portage)}{\code{@world}} on \href{https://www.gentoo.org/}{Gentoo},
the maturity of returning to Ubuntu \sc{lts} and delaying upgrades until the first dot one release,
and to the overwhelmed parent stage of becoming a happy macOS user.

\sc{unix} also became an essential building block in my profession.
Most of the software I wrote operates in a \sc{unix} environment, and I still consult my copy of \href{https://www.goodreads.com/book/show/603263.Advanced_Programming_in_the_UNIX_Environment}{Advanced Programming in the \sc{unix} Environment} by W. Richard Stevens and Stephen A. Rago from time to time.

\section{git}{Git}

\epigraph{
  It is easy to shoot your foot off with git, but also easy to revert to a previous foot and merge it with your current leg.
}{
  Jack William Bell
}

I encountered version control systems in early 2009; the company I worked for used \href{https://en.wikipedia.org/wiki/IBM_Rational_ClearCase}{Rational ClearCase} to manage their code.
The system versioned each file separately and relied on large configuration files---\em{config specs}---to construct a consistent snapshot of the source tree.
The tool was utterly confusing and intimidating, so I avoided dealing with it beyond the everyday operations.

About a year later, I joined a shop that used \href{https://subversion.apache.org/}{Subversion} for version control.
This time, I invested in learning upfront and swallowed the entire \href{https://svnbook.red-bean.com/}{Version Control with Subversion} before making my first commit.
Subversion was easy to understand and use; I couldn't imagine how to improve on it.
Still, I perceived it as a tool that you use at work.
There was enough friction in setting up a repository to hinder its use for small personal projects.
At the time, Google offered hosting on \href{https://code.google.com/}{Google Code}, but I didn't feel comfortable sharing my experiments with the world back then.

And then I discovered \href{https://git-scm.com/}{Git}.

Git was nothing like Subversion.
It had a steep learning curve and confused everyone around me to no end\sidenote{sn-git-random-man}{
  \href{https://github.com/Lokaltog}{Kim Ødegaard} created a \href{https://git-man-page-generator.lokaltog.net/}{service} that generates random man pages mocking Git's dense documentation style way before we all got used to ChatGPT.
}.
Still, the confusion was qualitatively different from what I experienced with ClearCase.
ClearCase is confusing like a Russian novel: All the characters have strange names, the plot is complex, and it doesn't end well.
Git is confusing like math: It slowly melts your brain and molds it into a \href{https://en.wikipedia.org/wiki/Tesseract}{tesseract}, giving access to higher dimensions.

Git removed the friction from using version control; there was no excuse not to version anything of value anymore.
Merging branches with Git didn't cause anxiety disorders.
The staging area---confusingly named \em{index}---became essential to my workflows.
But my favorite feature was the breathtaking beauty of Git's design, the elegant mix of distributed systems, acyclic graphs, and content-addressed storage.

Learning about Git's internals was so much fun that I became interested in the bits and bolts of other version control systems.
I travelled through time from \href{https://darcs.net/}{Darcs} to \href{https://www.mercurial-scm.org/}{Mercurial}, \href{https://www.bitkeeper.org/}{BitKeeper}, and the ultimate origin, \href{https://en.wikipedia.org/wiki/Source_Code_Control_System}{SCCS}.
I also built a toy one-file version control system while learning Rust.

Will Git ever be replaced with something better?
Just as it was hard to imagine an improvement over Subversion before Git came along, it's hard to imagine a significant improvement over Git now.
For me, Git's primary disadvantage is its snapshot-oriented structure which makes merges hard to reason about.
Git, Mercurial, and most other tools make it challenging to separate original code from the decisions that the person merging files had to make\sidenote{sn-janestreet-patch-vs-diff}{
  Jane Street created a separate review tool to address this problem.
  See, for example, the \href{https://blog.janestreet.com/patch-review-vs-diff-review-revisited/}{Patch review vs. diff review, revisited} blog article.
}.
Systems based on \href{https://en.m.wikibooks.org/wiki/Understanding_Darcs/Patch_theory}{patch theory}, such as \href{https://pijul.org/}{Pijul} and \href{https://darcs.net/}{Darcs}, might address these issues.

\section{emacs}{Emacs}

\epigraph{
  While any text editor can save your files, only Emacs can save your soul.
}{Per Abrahamsen}

I edited my first program when I was about twelve years old in a friendly blue screen of \href{https://en.wikipedia.org/wiki/Turbo_Pascal}{Turbo Pascal 7.0}.
The environment had little friction: no project or build configuration, no noticeable build time; you type your code and run it.
That was a perfect tool for learning.

My university used Pascal for introductory programming classes, so I continued using Turbo Pascal for my assignments.
Later courses introduced C++ and Java, for which we used \href{https://en.wikipedia.org/wiki/Visual_Studio#6.0_(1998)}{Visual Studio 6.0} and \href{https://en.wikipedia.org/wiki/JBuilder}{JBuilder}.
Although we learned to invoke compilers from the command line in a few classes, \sc{ide}s dominated my code-editing experience.

At my first programming job, I had to work remotely on a Solaris workstation.
Almost everyone in our group used \href{https://en.wikipedia.org/wiki/NEdit}{NEdit} to edit the code.
One day, I noticed a person whose editor looked markedly different from everyone else's; their background was dark, and the code glowed with bright colors.
To me, that was a sign of their superior technical knowledge.
A burning desire to learn how to customize my editor filled my soul.

The quest for customization led me to \href{https://www.vim.org/}{Vim} (the workstation had Vim 6 installed out of the box).
After all, if the goal is to stand out from the crowd, why stop at the color scheme?
I went through the Vim tutorial, and it clicked with me immediately.
It felt like playing a musical instrument: challenging but fun.
It turned a mundane job of fixing bugs into an exercise in skill.

I don't remember exactly when and why I got interested in Emacs\sidenote{sn-wolfram-notes}{
  One of the things I wish I started doing earlier is journaling daily.
  I'm nowhere near \href{https://writings.stephenwolfram.com/2019/02/seeking-the-productive-life-some-details-of-my-personal-infrastructure/#archiving-and-searching}{Stephen Wolfram's level}, but I enjoy going back and seeing what I was up to a few years ago.
}.
Most likely, it was a result of my obsession with Lisp after reading \href{https://en.wikipedia.org/wiki/Structure_and_Interpretation_of_Computer_Programs}{Structure and Interpretation of Computer Programs} and looking for a Lisp to interact with.
I remember reading \href{https://www.gnu.org/software/emacs/manual/eintr.html}{An Introduction to Programming in Emacs Lisp} around 2010 and having a lot of fun.

I became interested in the editor internals.
Using \href{https://www.finseth.com/craft/}{The Craft of Text Editing} by Craig A. Finseth as a guide, I explored the source code of various editors to see how they worked: which the data structures they used to represent text buffers, how they implemented the undo mechanism.
I found Vim's source code somewhat messy and hard to understand.
Emacs's source was clean, consistent, well-organized, and well-documented.

A dive into Emacs internals also revealed the inherent beauty of its architecture.
Emacs is a Lisp machine that provides text editing and window management capabilities.
It is a powerful, convenient, and friendly development environment for building dynamic text-driven applications in Emacs Lisp.

Almost everything in Emacs is a Lisp object you can inspect, interact with, and access its documentation.
That makes Emacs' documentation system unparalleled once you master it.
Emacs' dynamism and closeness to the user make extending it much easier than any other editor.
The feedback loop is airtight: you can immediately try out your code in the context of the editor you use to write it.

While I'm writing these words in \href{https://code.visualstudio.com/}{Visual Studio Code}, I always have my Emacs open\sidenote{sn-vim}{
  I also have a \href{https://github.com/tmux/tmux/wiki}{tmux} session with multiple \href{https://neovim.io/}{nvim} instances running.
  I use these when my pinky gets tired of holding down the \kbd{Ctrl} key.
}.
Many things are easier in Emacs; I don't think any software will ever completely replace it for me.
It's also my editor of choice if I need to implement an extension: Programming Emacs Lisp is a joy.

\section{boost-graph}{Boost.Graph}

\epigraph{
  I also must confess to a strong bias against the fashion for reusable code.
  To me, ``re-editable code'' is much, much better than an untouchable black box or toolkit.
}{
  Donald Knuth, \href{https://www.informit.com/articles/article.aspx?p=1193856}{Interview with Andrew Binstock}
}

The evening of New Year's Eve in 2013 didn't go as planned.
I was on a cruise ship crossing the stormy Baltic Sea and couldn't stay on my feet because of the seasickness.
Instead of consuming tasty treats with the rest of the passengers, I was lying in bed and reading a book I took for the trip: \href{https://www.goodreads.com/book/show/1705806.The_Boost_Graph_Library}{The Boost Graph Library} by Jeremy G. Siek et al.

Most algorithm libraries require you to commit to a specific data representation, making integrating them into an existing project prohibitively expensive.
That's especially true for graph algorithms: The vertices and edges are usually implicitly defined and deeply embedded into other data structures, so it's easier to re-implement the algorithm than to use a generic library.

The \href{https://www.boost.io/libraries/graph/}{Boost.Graph} library offers an elegant solution to this problem based on \href{https://en.wikipedia.org/wiki/Alexander_Stepanov}{Alex Stepanov}'s ideas on generic programming.
It uses a bag of tricks (type traits, property maps, visitors) to implement graph algorithms that will work on almost any graph representation you throw at them, given that you provide an adapter telling the library how to view your data structures as a graph.

Even though I never had a chance to use the library in practice\sidenote{sn-boost-graph-use}{
  Given that I share Donald Knuth's attitude opening this section, I would probably not use the library even if I had a chance.
  I'd rather write one page of interesting code traversing a graph than two pages of boring adapters required to invoke the algorithm.
}, its design helped me deepen my understanding of \href{https://en.wikipedia.org/wiki/Standard_Template_Library}{\sc{stl}} design and generic programming in general.
It also helped me understand the motivation for advanced type-level programming features in other programming languages, such as \href{https://wiki.haskell.org/GHC/Type_families}{type families} in Haskell.
Overall, Boost.Graph is one of the most enlightening software that I've never used.

\section{bazel}{Bazel}

I wrote my first \code{Makefile} around 2009 while working on a research project in computational mathematics for my cybernetics degree.
I used \href{https://en.wikipedia.org/wiki/Make_(software)}{\code{make}} at work, but I didn't need to understand how it worked.
This time, I had to compile a \sc{fortran} program from various modules adhering to different language standards: from venerable \sc{fortran} 77 to hip Fortran 2003.
To get a deeper understanding of the tool, I dived into \href{https://www.oreilly.com/library/view/managing-projects-with/0596006101/}{Managing Projects with GNU Make} by Robert Mecklenburg.

Reading a book on technology usually excites me; I become enthusiastic about the topic and want to try it out in practice. 
The book on \code{make} had the opposite effect.
The complexity required to make builds correct and ergonomic made me earn for a better tool\sidenote{sn-modern-cpp-design}{
  One book that made me feel the same way was \href{https://www.goodreads.com/book/show/871669.Modern_C_Design}{Modern C++ Design} by Andrei Alexandrescu.
  The book is deep and beautifully written, but the terrifyingly clever and ugly tricks in the second chapter made me question the choice of the programming language.
  Another one is \href{https://nostarch.com/autotools2e}{Autotools} by John Calcote.
}.

Since my first exposure to \code{make}, I often fiddled with build systems at work:
I introduced \href{https://cmake.org/}{CMake} to a C++ project to replace a bunch of complex and scarily incorrect \code{Makefile} files and
replaced an inflexible \href{https://ant.apache.org/}{Ant}-based build system in a 500 \sc{kloc} Java project with \href{https://gradle.org/}{Gradle}.
But all of the tools I tried, including \href{https://cmake.org/}{CMake}, \href{https://ant.apache.org/}{Ant}, \href{https://maven.apache.org/}{Maven}, \href{https://gradle.org/}{Gradle}, \href{https://www.scons.org/}{SCons}, and \href{https://www.gnu.org/software/automake/manual/html_node/Autotools-Introduction.html}{autotools} left me deeply unsatisfied.
They were clanky, awkward, and hard to extend and compose.

In 2016, I joined Google in Zurich.
I heard about the internal build tool, \code{blaze}, and couldn't wait to lay my hands on it.
Surprisingly, I didn't need to fiddle with \code{blaze}.
Nor did I have to understand how it worked.
I could copy some build targets and edit the dependency list, and the build worked as expected.
\code{blaze} made correct and fast builds not just easy, but \em{boring} in the good sense.
Only a few years later, when I attempted to use \href{https://bazel.build/}{Bazel}---the open-source version of \code{blaze}---for a toy personal project, did I have to understand the underlying model.

Bazel was the third and final piece of the puzzle, together with Haskell's core typeclasses and the \href{https://www.tensorflow.org/}{TensorFlow} 1.0 execution model, that made me understand the ubiquitous plan-execute pattern\sidenote{sn-build-systems-a-la-carte}{
  The \href{https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf}{Build Systems à la Carte} article by Andrey Mokhov, Neil Mitchell, and Simon Peyton Jones explains in detail how various build system designs map to Haskell typeclasses.
}.
Bazel build file is a program that constructs a slice of the build artifact graph.
Bazel rules don't run the build commands; they declare how to transform inputs into outputs, and the Bazel engine figures out the rest.

My relationship with the tool reached true intimacy when I helped \href{/posts/17-scaling-rust-builds-with-bazel.html}{transition \sc{dfinity}'s build system to Bazel}.
Despite all the challenges I faced, Bazel still is my favorite build system.
It's fast, correct, easy to use, and language-agnostic.

Yet, I think a smaller, simpler, cleaner build system design is buried in Bazel's complexity.
I hope this core will someday reveal itself to the world and become the standard tool for building all software.

\section{conclusion}{Conclusion}

\end{document}